# Final Year Project (Image Captioning)

As technology improves as the years goes on, the image captioning technology improves along the way as well. We have im2txt from Google, neuraltalk2 by Andrej Karpathy and so much more. What I am trying to do is basically using video, split them into frame by frame and decode it using these technologies. I managed to garner 4 image captioning models and generate a caption from them. 

However, it doesn't make any sense to have 4 captions in the video and thus i decided to create a GUI to allow users from running the script that creates the 4 captions to be able to select which is the most accurate caption! Or we can allow the user to type in their own captions as well. 

Although, the user would have to follow the caption style that is used in most of the NLP Module. I believe that this is the best way to do it thus far. After the user key in the caption, it will be great to retrain the model which is what i will be doing right after.

# The overall flow of the software is as follow:

* Running the caption.sh file with the following command
`./caption.sh <video_file> <image_folder>`

With that you would be able to run the 4 models and depending on the size of the video and the amount of image produce will take a range of 2-4 hours. It is helpful to use screen to run the program in the background because it takes forever sometimes in a Programmer world. 

After that it will load the python gui in the below example which allow you to select the most accurate caption generated by the software. This will be updated to allow you to key in the caption that you have the caption that you want in the video!

It is still a beta prototype which I am still figuring out how to improve. 

# GUI Example 
Note that this is not the complete one. This is just an example that i did thus far using python tkinter code which is available to read at this repository at fyp_gui.

![alt text](https://i.imgur.com/7hdU8vI.png)

# Web Example 

This is an example of what we will see in the web example where we search for a certain keyword as well as the caption running from the json file in the index.html file after its loaded from the loadvid.js file

![alt text](https://i.imgur.com/iAP1Pk2.png)

Video tested with Singapore Airlines Safety Video

# Credits 
Credits got to go to credit due. 

im2txt - Google
Neuraltalk2 - Andrej Karpathy, Stanford

