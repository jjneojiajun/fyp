# Final Year Project (Image Captioning)

As technology improves as the years goes on, the image captioning technology improves along the way as well. We have im2txt from Google, neuraltalk2 by Andrej Karpathy and so much more. What I am trying to do is basically using video, split them into frame by frame and decode it using these technologies. I managed to garner 4 image captioning models and generate a caption from them. 

However, it doesn't make any sense to have 4 captions in the video and thus i decided to create a GUI to allow users from running the script that creates the 4 captions to be able to select which is the most accurate caption! Or we can allow the user to type in their own captions as well. 

Although, the user would have to follow the caption style that is used in most of the NLP Module. I believe that this is the best way to do it thus far. After the user key in the caption, it will be great to retrain the model which is what i will be doing right after.

# Example 
Note that this is not the complete one. This is just an example that i did thus far using python tkinter code which is available to read at this repository at fyp_gui.

![alt text](https://i.imgur.com/NQPcycM.png)

# Credits 
Credits got to go to credit due. 

im2txt - Google
Neuraltalk2 - Andrej Karpathy, Stanford

